{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a7b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import os\n",
    "import spacy\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ab8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765f5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632b6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the content of a PDF file\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        for page_number in range(pdf_reader.getNumPages()):\n",
    "            page = pdf_reader.getPage(page_number)\n",
    "            text += page.extractText()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62487150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the content of a Word file\n",
    "def read_word(file_path):\n",
    "    text = \"\"\n",
    "    doc = Document(file_path)\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbe9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    processed_text = text.lower()\n",
    "\n",
    "    # Strip leading and trailing spaces\n",
    "    processed_text = processed_text.strip()\n",
    "\n",
    "    # Remove HTML tags using a regex pattern\n",
    "    processed_text = re.sub(r'<.*?>', '', processed_text)\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    processed_text = re.sub(r'[^\\w\\s]', ' ', processed_text)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "\n",
    "    # Remove square brackets and their contents\n",
    "    processed_text = re.sub(r'\\[.*?\\]', '', processed_text)\n",
    "\n",
    "    # Remove non-alphanumeric characters\n",
    "    processed_text = re.sub(r'[^a-zA-Z0-9\\s]', '', processed_text)\n",
    "\n",
    "    # Remove digits\n",
    "    processed_text = re.sub(r'\\d', '', processed_text)\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    processed_text = ' '.join(processed_text.split())\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797bb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of your 'charge.txt' file\n",
    "file_path = 'C:/Users/COULIBALY KHADER/Desktop/TP learning/charge.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f59790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the file extension and read the content based on its type\n",
    "file_extension = os.path.splitext(file_path)[1].lower()\n",
    "if file_extension == '.pdf':\n",
    "    content = read_pdf(file_path)\n",
    "elif file_extension == '.docx':\n",
    "    content = read_word(file_path)\n",
    "elif file_extension == '.txt':\n",
    "    with open(file_path, 'r', encoding='utf-8') as txt_file:\n",
    "        content = txt_file.read()\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8cf438b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_848\\560502242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Create a conversation with GPT-3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     response = openai.Completion.create(\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text-davinci-002\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# You can use the model of your choice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    113\u001b[0m         )\n\u001b[0;32m    114\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         )\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             return (\n\u001b[1;32m--> 396\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    397\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                 ),\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    430\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "# Preprocess the content\n",
    "processed_text = preprocess_text(content)\n",
    "\n",
    "# Define a function to extract requirements from preprocessed text\n",
    "def extract_requirements(text):\n",
    "    # Initialize an empty list to store the extracted requirements\n",
    "    requirements = []\n",
    "\n",
    "    # Define keywords or patterns that indicate a requirement\n",
    "    requirement_keywords = [\"contractor\", \"shall\", \"provide\", \"requirement\"]\n",
    "\n",
    "    # Split the preprocessed text into lines or paragraphs\n",
    "    lines = text.split('\\n')  # Adjust the delimiter as needed\n",
    "\n",
    "    # Iterate through the lines\n",
    "    for line in lines:\n",
    "        # Check if the line contains a requirement keyword\n",
    "        if any(keyword in line.lower() for keyword in requirement_keywords):\n",
    "            # If a keyword is found, add the line to the list of requirements\n",
    "            requirements.append(line)\n",
    "\n",
    "    return requirements\n",
    "\n",
    "# Extract requirements from the processed text\n",
    "extracted_requirements = extract_requirements(processed_text)\n",
    "\n",
    "# Initialize a list to store generated requirements\n",
    "generated_requirements = []\n",
    "\n",
    "# Use OpenAI's GPT-3 to assist with requirement generation\n",
    "for requirement in extracted_requirements:\n",
    "    user_prompt = f\"Generate a more detailed requirement based on the following text:\\n{requirement}\\n\"\n",
    "\n",
    "    # Create a conversation with GPT-3\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",  # You can use the model of your choice\n",
    "        prompt=user_prompt,\n",
    "        max_tokens=50,  # Adjust the maximum number of tokens as needed\n",
    "        stop=None  # You can specify a list of strings to stop generation\n",
    "    )\n",
    "\n",
    "    # Extract the generated requirement and add it to the list\n",
    "    generated_requirement = response.choices[0].text.strip()\n",
    "    generated_requirements.append(generated_requirement)\n",
    "\n",
    "# Print the generated requirements\n",
    "for i, requirement in enumerate(generated_requirements, 1):\n",
    "    print(f\"Generated Requirement {i}: {requirement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your preprocessed text from a JSON file (modify the file path as needed)\n",
    "with open('C:/Users/COULIBALY KHADER/Desktop/TP learning/data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words in the text\n",
    "word_count = len(preprocessed_content.split())\n",
    "print(\"Word Count:\", word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e3111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count characters in the text\n",
    "character_count = len(preprocessed_content)\n",
    "print(\"Character Count:\", character_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    \"The Contractor shall have a bachelor's degree in science such as Business, Information ,Technology Administration, or Health Sciences\",\n",
    "    \"The Contractor shall provide Program Management Support Services to AFMRA/SG5 as described in the following paragraphs by task\",\n",
    "    \"The contractor shall provide one mid-senior level Executive Administrative Support to two Government executives and approximately 40 personnel within the SG5 Capability DevelopmentDivision, located at Defense Health Headquarters (DHHQ), 7700 Arlington Blvd., Falls Church, VA\",\n",
    "    \"http://www.defensetravel.dod.mil/Docs/perdiem/JTR.pdf. \",\n",
    "    \"Contractor shall provide three mid-level and one senior-level Requirement Management (RM) Analysts to assist in requirements development and management services in support of AFMRA/SG5R located at DHHQ, Falls Church, VA\",\n",
    "    \"The Contractor shall provide personnel with the minimum qualifications listed below\",\n",
    "    \"The Contractor shall have an associate degree in science such as communication, business management or administration, or related degree\",\n",
    "    \"The contractor shall have a minimum of 4 years of related work experience in preparing and editing executive documents\",\n",
    "    \"The contractor shall have a minimum of 4 years of related work experience in working with senior level DoD, other federal government agencies, or private sector companies\",\n",
    "    \"The contractor shall have an associate degree in Administration, Management, Education, Information Technology or similar degree\"\n",
    "]\n",
    "labels = [\"Positive\", \"Positive\", \"Positive\", \"Negative\", \"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Positive\", \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575dbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1626b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a text classifier (e.g., Multinomial Naive Bayes)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training data\n",
    "y_train_pred = classifier.predict(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d596d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_test_pred = classifier.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier on the training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_classification_rep = classification_report(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier on the test data\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_classification_rep = classification_report(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0de96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the results for both training and testing data\n",
    "print(\"Training Data Results:\")\n",
    "print(f\"Accuracy: {train_accuracy}\")\n",
    "print(f\"Classification Report:\\n{train_classification_rep}\")\n",
    "\n",
    "print(\"\\nTesting Data Results:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Classification Report:\\n{test_classification_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec7fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Access the 'requirements' key from the JSON data\n",
    "requirements_data = data.get(\"properties\", {}).get(\"requirements\", [])\n",
    "\n",
    "# Convert the list of preprocessed_text into a single string\n",
    "preprocessed_text = ' '.join(preprocessed_text)\n",
    "\n",
    "# Loop through each requirement and compare with preprocessed_text\n",
    "for requirement in requirements_data:\n",
    "    extracted_requirements = requirement.get(\"extracted_requirements\")\n",
    "    requirement_type = requirement.get(\"requirement_type\")\n",
    "    original_context = requirement.get(\"original_context\")\n",
    "    rfp_domain = requirement.get(\"rfp_domain\")\n",
    "    requirement_domain = requirement.get(\"requirement_domain\")\n",
    "    confidence_factor = requirement.get(\"confidence_factor\")\n",
    "    related_requirements = requirement.get(\"related_requirements\")\n",
    "\n",
    "    # Check if the preprocessed text contains the extracted requirement\n",
    "    if extracted_requirements in preprocessed_text:\n",
    "        print(\"\\nOriginal Context:\", original_context)\n",
    "        print(\"Requirement Type:\", requirement_type)\n",
    "        print(\"RFP Domain:\", rfp_domain)\n",
    "        print(\"Requirement Domain:\", requirement_domain)\n",
    "        print(\"Confidence Factor:\", confidence_factor)\n",
    "        print(\"Related Requirements:\", related_requirements)\n",
    "\n",
    "        # Print the extracted requirement without numbering\n",
    "        print(\"\\nExtracted Requirements:\", extracted_requirements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
